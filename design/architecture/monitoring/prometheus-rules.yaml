apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: gmc-o-prod
data:
  gmc-o-alerts.yaml: |
    groups:
    - name: gmc-o-critical
      interval: 30s
      rules:
      # Latency Alerts
      - alert: HighP99Latency
        expr: histogram_quantile(0.99, sum(rate(inference_latency_seconds_bucket[5m])) by (le)) > 0.100
        for: 5m
        labels:
          severity: critical
          component: gpu-inference
        annotations:
          summary: "p99 latency exceeds 100ms SLA"
          description: "p99 latency is {{ $value | humanizeDuration }} (threshold: 100ms)"
          runbook: "https://runbooks.example.com/high-latency"

      - alert: HighP50Latency
        expr: histogram_quantile(0.50, sum(rate(inference_latency_seconds_bucket[5m])) by (le)) > 0.050
        for: 10m
        labels:
          severity: warning
          component: gpu-inference
        annotations:
          summary: "p50 latency degraded"
          description: "p50 latency is {{ $value | humanizeDuration }} (threshold: 50ms)"

      # Cache Alerts
      - alert: LowCacheHitRate
        expr: sum(rate(cache_hits_total[10m])) / sum(rate(cache_requests_total[10m])) < 0.90
        for: 10m
        labels:
          severity: warning
          component: redis
        annotations:
          summary: "Cache hit rate dropped below 90%"
          description: "Current hit rate: {{ $value | humanizePercentage }}"
          runbook: "https://runbooks.example.com/low-cache-hit"

      - alert: CriticalCacheHitRate
        expr: sum(rate(cache_hits_total[5m])) / sum(rate(cache_requests_total[5m])) < 0.70
        for: 5m
        labels:
          severity: critical
          component: redis
        annotations:
          summary: "Cache hit rate critically low"
          description: "Current hit rate: {{ $value | humanizePercentage }}"

      # GPU Health Alerts
      - alert: GPUNodeDown
        expr: up{job="gpu-shard"} == 0
        for: 2m
        labels:
          severity: critical
          component: gpu-node
        annotations:
          summary: "GPU node {{ $labels.instance }} is down"
          description: "Node has been down for 2 minutes"
          runbook: "https://runbooks.example.com/gpu-node-down"

      - alert: GPUMemoryHigh
        expr: gpu_memory_used_bytes / gpu_memory_total_bytes > 0.95
        for: 5m
        labels:
          severity: warning
          component: gpu-memory
        annotations:
          summary: "GPU memory usage critical on {{ $labels.instance }}"
          description: "Memory usage: {{ $value | humanizePercentage }}"

      - alert: GPUTemperatureHigh
        expr: gpu_temperature_celsius > 85
        for: 5m
        labels:
          severity: warning
          component: gpu-thermal
        annotations:
          summary: "GPU temperature high on {{ $labels.instance }}"
          description: "Temperature: {{ $value }}°C (threshold: 85°C)"

      # Shard Health Alerts
      - alert: ShardUnhealthy
        expr: sum(shard_health_status) by (shard_id) < 2
        for: 1m
        labels:
          severity: critical
          component: shard-replication
        annotations:
          summary: "Shard {{ $labels.shard_id }} has <2 healthy replicas"
          description: "Only {{ $value }} replica(s) healthy (required: 2)"
          runbook: "https://runbooks.example.com/shard-unhealthy"

      - alert: ShardReplicationLag
        expr: shard_replication_lag_seconds > 2
        for: 5m
        labels:
          severity: warning
          component: shard-replication
        annotations:
          summary: "Shard {{ $labels.shard_id }} replication lag high"
          description: "Lag: {{ $value | humanizeDuration }}"

      # Throughput Alerts
      - alert: LowThroughput
        expr: sum(rate(inference_request_total[5m])) < 100000
        for: 10m
        labels:
          severity: warning
          component: throughput
        annotations:
          summary: "Request throughput below expected baseline"
          description: "Current RPS: {{ $value | humanize }}"

      - alert: HighErrorRate
        expr: sum(rate(inference_errors_total[5m])) / sum(rate(inference_request_total[5m])) > 0.01
        for: 5m
        labels:
          severity: critical
          component: error-rate
        annotations:
          summary: "Error rate exceeds 1%"
          description: "Current error rate: {{ $value | humanizePercentage }}"
          runbook: "https://runbooks.example.com/high-error-rate"

      # Redis Alerts
      - alert: RedisNodeDown
        expr: up{job="redis-cluster"} == 0
        for: 1m
        labels:
          severity: critical
          component: redis
        annotations:
          summary: "Redis node {{ $labels.instance }} is down"
          description: "Node has been down for 1 minute"

      - alert: RedisMemoryHigh
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.90
        for: 5m
        labels:
          severity: warning
          component: redis-memory
        annotations:
          summary: "Redis memory usage high on {{ $labels.instance }}"
          description: "Memory usage: {{ $value | humanizePercentage }}"

      # Capacity Planning Alerts
      - alert: GPUUtilizationHigh
        expr: avg(gpu_utilization_percent) > 80
        for: 30m
        labels:
          severity: warning
          component: capacity
        annotations:
          summary: "Average GPU utilization high - consider scaling"
          description: "Average utilization: {{ $value }}%"

      - alert: EnvoyProxyOverload
        expr: sum(rate(envoy_http_downstream_rq_total[5m])) / count(up{job="envoy-proxy"}) > 25000
        for: 10m
        labels:
          severity: warning
          component: capacity
        annotations:
          summary: "Envoy proxies handling high load - consider scaling"
          description: "Average RPS per proxy: {{ $value | humanize }}"

    - name: gmc-o-performance
      interval: 60s
      rules:
      # Recording rules for dashboards
      - record: job:inference_latency_seconds:p50
        expr: histogram_quantile(0.50, sum(rate(inference_latency_seconds_bucket[5m])) by (le, job))

      - record: job:inference_latency_seconds:p95
        expr: histogram_quantile(0.95, sum(rate(inference_latency_seconds_bucket[5m])) by (le, job))

      - record: job:inference_latency_seconds:p99
        expr: histogram_quantile(0.99, sum(rate(inference_latency_seconds_bucket[5m])) by (le, job))

      - record: job:cache_hit_rate:5m
        expr: sum(rate(cache_hits_total[5m])) by (job) / sum(rate(cache_requests_total[5m])) by (job)

      - record: job:requests_per_second:5m
        expr: sum(rate(inference_request_total[5m])) by (job)

      - record: job:error_rate:5m
        expr: sum(rate(inference_errors_total[5m])) by (job) / sum(rate(inference_request_total[5m])) by (job)

      - record: shard:gpu_utilization:avg
        expr: avg(gpu_utilization_percent) by (shard_id)

      - record: shard:memory_usage:avg
        expr: avg(gpu_memory_used_bytes / gpu_memory_total_bytes) by (shard_id)
