# Neo4j Vector Search: Comprehensive Research Analysis

**Research Date**: December 4, 2025
**Focus**: Neo4j v5.11+ vector search capabilities vs Milvus comparison
**Prepared By**: Research Agent

---

## Executive Summary

Neo4j introduced native vector search capabilities in August 2023 (v5.11+) using HNSW (Hierarchical Navigable Small World) algorithm. While Neo4j offers hybrid graph + vector search capabilities, it remains fundamentally a graph database with vector search as an extension, not a purpose-built vector database like Milvus. **Key finding**: No published benchmarks exist comparing Neo4j vs Milvus at 100M+ vector scale.

---

## 1. Neo4j Vector Index Overview

### 1.1 Release Timeline

- **Initial Release**: August 2023 (Neo4j v5.11)
- **Native Vector Type**: Introduced with v5.11+ as a first-class data type
- **Quantization Support**: Added in v5.11 with default-enabled quantization
- **Dimension Expansion**: v5.23 (vector-2.0) made `vector.dimensions` optional
- **Current Status**: Production-ready as of 2024

**Source**: [Neo4j Blog - Native Vector Data Type](https://neo4j.com/blog/developer/introducing-neo4j-native-vector-data-type/)

### 1.2 Algorithm Implementation

**Primary Algorithm**: HNSW (Hierarchical Navigable Small World)

- **Implementation**: Uses Apache Lucene's HNSW implementation
- **Graph Structure**: Multi-layer k-nearest neighbor graphs
- **Search Type**: Approximate Nearest Neighbor (ANN)

**Configurable HNSW Parameters**:

```cypher
CREATE VECTOR INDEX index_name FOR (n:Node) ON n.embedding
OPTIONS {
  indexConfig: {
    `vector.dimensions`: 1536,
    `vector.similarity_function`: 'cosine',
    `vector.hnsw.m`: 16,                    // Max connections per node
    `vector.hnsw.ef_construction`: 200,     // Neighbors tracked during insertion
    `vector.quantization.enabled`: true     // Quantization on/off
  }
}
```

**Sources**:
- [Neo4j Cypher Manual - Vector Indexes](https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/vector-indexes/)
- [Neo4j 5 Changelog](https://github.com/neo4j/neo4j/wiki/Neo4j-5-changelog)

---

## 2. Technical Specifications

### 2.1 Dimensions and Scale

| Specification | Neo4j Limit | Notes |
|---------------|-------------|-------|
| **Max Dimensions** | 4,096 | Users requested 8,192 support (pending) |
| **Min Dimensions** | 1 | INTEGER only |
| **Similarity Functions** | Cosine, Euclidean | Limited compared to dedicated vector DBs |
| **Tested Scale** | Not documented | No public benchmarks at 100M+ scale |

**Historical Evolution**:
- Early 2024: 2,048 dimension limit
- Mid 2024: 4,096 dimension limit (current)
- Future: 8,192 requested by users

**Sources**:
- [GitHub Issue #13406 - Dimension Limit 2048](https://github.com/neo4j/neo4j/issues/13406)
- [GitHub Issue #13512 - Increase to 8192](https://github.com/neo4j/neo4j/issues/13512)

### 2.2 GPU Acceleration

**Status**: ‚ùå **Not Supported**

Neo4j's vector search does **not** have native GPU acceleration. Research exists on GPU-accelerating graph queries, but vector search specifically runs on CPU only.

**Evidence**:
- Academic thesis on GPU-accelerating graph pattern queries (not vector search)
- Community forum discussions indicate no official GPU support
- HNSW implementation via Lucene is CPU-based

**Third-Party Comparison**:
- NornicDB (alternative) with Apple Metal GPU: 1.6-4.9x faster than Neo4j
- 35-47% additional boost from GPU acceleration (not available in Neo4j)

**Sources**:
- [GitHub - neo4j-gpu (Research Project)](https://github.com/SimonEjenstam/neo4j-gpu)
- [Neo4j Community - GPU Use Discussion](https://community.neo4j.com/t/gpu-use-in-improving-the-calculating-speed-of-algorithms/19439)

### 2.3 Quantization Support

**Status**: ‚úÖ **Basic Quantization Supported**

```cypher
CREATE VECTOR INDEX WITH OPTIONS {
  `vector.quantization.enabled`: true  // Default: true for new indexes
}
```

**Quantization Type**: General vector quantization (unspecified method)

**Comparison with Specialized Vector DBs**:

| Database | Quantization Types |
|----------|-------------------|
| **Neo4j** | Generic quantization (method unspecified) |
| **Milvus** | Scalar Quantization (SQ), Product Quantization (PQ), Binary Quantization |
| **Qdrant** | Scalar, Product, Binary quantization |
| **Weaviate** | Product Quantization, Binary Quantization |

**Performance Impact**:
- ‚úÖ Reduces memory footprint
- ‚úÖ Accelerates search performance
- ‚ö†Ô∏è Slightly decreases accuracy
- üìä Recommended for memory-constrained machines

**Source**: [Neo4j Cypher Manual - Vector Indexes](https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/vector-indexes/)

---

## 3. Performance Benchmarks

### 3.1 ANN Benchmarks

**Status**: ‚ùå **Not Included in Standard ANN Benchmarks**

Neo4j does **not** appear in the official [ANN-Benchmarks](http://ann-benchmarks.com/) comparison suite.

**Algorithms Tested in ANN-Benchmarks**:
- hnswlib
- hnsw(faiss)
- hnsw(nmslib)
- hnsw(vespa)
- pgvector
- annoy
- scann

**Neo4j Absence**: Likely because it's a graph database first, not a dedicated vector search library.

### 3.2 Neo4j vs Milvus: QPS and Latency

**Critical Gap**: ‚ö†Ô∏è **No Direct Published Benchmarks**

After extensive research, **no published benchmarks compare Neo4j vs Milvus** for vector search at 100M scale.

#### Milvus Published Performance

**Milvus 2.2 Benchmarks** (from official documentation):

| Metric | Value | Dataset |
|--------|-------|---------|
| **Query Time** | <10ms | 1M vectors, 100D, HNSW + GPU |
| **Query Time** | 20-50ms | 100M vectors (estimated) |
| **Latency** | <2ms | Optimal conditions |
| **QPS Improvement** | +48% (cluster), +75% (standalone) | vs Milvus 2.1 |
| **Scalability** | Linear QPS growth | 8-32 CPU cores |

**Milvus LAION 100M Benchmark** (VectorDBBench):
- **Dataset**: 100M vectors √ó 768 dimensions
- **Metrics**: Index build time, recall, latency, max QPS
- **Results**: Documented in VectorDBBench tool

**Sources**:
- [Milvus 2.2 Benchmark Report](https://milvus.io/docs/benchmark.md)
- [VectorDBBench GitHub](https://github.com/zilliztech/VectorDBBench)

#### Neo4j Published Performance

**Available Data**:
- Community example: 10M nodes indexed (small scale, not 100M)
- No official 100M vector benchmark
- Performance documentation focuses on graph queries, not vector search

**Third-Party Comparison** (NornicDB vs Neo4j):
- NornicDB (graph DB): 1.6-4.9x faster than Neo4j
- GPU acceleration: +35-47% boost (not available in Neo4j)

**Sources**:
- [Medium - 10M Nodes Performance](https://medium.com/@kanishksinghpujari/we-indexed-10-million-nodes-in-neo4j-heres-what-happened-to-search-performance-9cd101602560)
- [NornicDB Benchmark vs Neo4j](https://github.com/orneryd/Mimir/blob/main/nornicdb/BENCHMARK_RESULTS_VS_NEO4J.md)

#### VectorDBBench Coverage

**Included Databases**:
- Milvus
- Zilliz Cloud
- Elastic Search
- Qdrant Cloud
- Weaviate Cloud
- PgVector
- Redis
- Chroma
- CockroachDB

**Notable Absence**: ‚ùå Neo4j

**Reason**: Neo4j is not a purpose-built vector database, so it's excluded from specialized vector DB benchmarking tools.

### 3.3 Benchmark Summary

| Aspect | Neo4j | Milvus |
|--------|-------|--------|
| **ANN Benchmarks** | Not included | Included |
| **100M Vector Benchmarks** | Not published | Published (VectorDBBench) |
| **Official Documentation** | Graph-focused | Vector-focused |
| **Community Benchmarks** | Limited (10M scale) | Extensive (100M+ scale) |

---

## 4. Integration Patterns

### 4.1 Hybrid Graph + Vector Queries

**Status**: ‚úÖ **Unique Strength of Neo4j**

Neo4j's killer feature is **HybridCypherRetriever** - combining vector search with graph traversal.

#### Architecture

```
1. Vector Similarity Search ‚Üí Initial Node Set
2. Graph Traversal (Cypher) ‚Üí Related Nodes + Context
3. Result Merging ‚Üí Enriched Data for LLM
```

#### Example Use Case

```cypher
// 1. Find similar documents via vector search
CALL db.index.vector.queryNodes('document_embeddings', 5, $queryVector)
YIELD node AS doc, score

// 2. Traverse graph to get authors and citations
MATCH (doc)-[:WRITTEN_BY]->(author)
MATCH (doc)-[:CITES]->(cited)

// 3. Return enriched context
RETURN doc.title, author.name, collect(cited.title) AS citations, score
ORDER BY score DESC
```

#### Components

1. **Vector Similarity**: Semantic search over embeddings
2. **Full-Text Search**: Keyword-based search (optional)
3. **Graph Traversal**: Relationship-based context expansion
4. **Result Fusion**: Combined ranking and deduplication

**Use Cases**:
- **GraphRAG** (Graph-enhanced RAG pipelines)
- **Knowledge Graph Q&A**: "Find papers similar to X written by collaborators of Y"
- **Recommendation Systems**: Content similarity + social graph
- **Entity Linking**: Semantic match + relationship validation

**Sources**:
- [GraphAcademy - Hybrid Retrieval](https://graphacademy.neo4j.com/courses/genai-workshop-graphrag/2-neo4j-graphrag/5-hybrid-cypher-retriever/)
- [Neo4j Blog - GraphRAG Python Package](https://neo4j.com/blog/developer/enhancing-hybrid-retrieval-graphrag-python-package/)

### 4.2 Vector-on-Graph Nodes

**Status**: ‚úÖ **Fully Supported**

Vectors can be stored as properties on graph nodes:

```cypher
// Create node with vector property
CREATE (p:Product {
  name: 'Laptop',
  embedding: [0.1, 0.2, ..., 0.768]  // 768-dimensional vector
})

// Create vector index
CREATE VECTOR INDEX product_embeddings
FOR (p:Product) ON p.embedding
OPTIONS {
  indexConfig: {
    `vector.dimensions`: 768,
    `vector.similarity_function`: 'cosine'
  }
}

// Query similar products
MATCH (p:Product)
CALL db.index.vector.queryNodes('product_embeddings', 10, $queryVector)
YIELD node AS similar, score
RETURN similar.name, score
```

### 4.3 Batch Operations

**Status**: ‚úÖ **Supported via Cypher**

```cypher
// Batch insert with UNWIND
UNWIND $batch AS item
CREATE (n:Document {
  id: item.id,
  text: item.text,
  embedding: item.embedding
})

// Batch vector search (limited by query design)
WITH [vector1, vector2, vector3] AS queryVectors
UNWIND queryVectors AS qv
CALL db.index.vector.queryNodes('doc_index', 5, qv)
YIELD node, score
RETURN node, score
```

**Limitations**:
- No dedicated bulk insert API like Milvus
- Performance may degrade with large batches
- Recommend batches of 1,000-10,000 nodes

---

## 5. Production Usage

### 5.1 Case Studies

#### Verified Production Use Cases

**Pharmaceutical Industry**:
- **Metric**: 75% reduction in regulatory report automation time
- **Technique**: Context-aware entity linking

**Insurance**:
- **Metric**: 90% faster customer inquiry response rate
- **Implementation**: Vector search for policy matching

**Banking**:
- **Metric**: 46% boost in legal contract review efficiency
- **Technique**: Vector similarity search on contracts

**Source**: [Neo4j Press Release - Vector Search](https://neo4j.com/press-releases/neo4j-vector-search/)

#### General Neo4j Production Adoption

- **Fortune 100**: 75+ companies use Neo4j (graph DB, not necessarily vector search)
- **Notable Users**: Adidas, Walmart, Gilt Groupe (use graph features, vector search adoption unclear)

**Development Process**:
- Neo4j consulted ~12 major customers for generative AI feature input
- Vector search announced August 2023 after customer consultation

**Source**: [TechTarget - Neo4j Vector Search](https://www.techtarget.com/searchdatamanagement/news/366549617/Neo4j-adds-vector-search-to-improve-generative-AI-outputs)

### 5.2 Known Limitations

Based on research and comparison with specialized vector databases:

1. **Scale Uncertainty**:
   - ‚ùå No public benchmarks at 100M+ vector scale
   - ‚ö†Ô∏è Largest documented example: 10M nodes
   - ‚ùì Unknown performance characteristics beyond 10M scale

2. **GPU Acceleration**:
   - ‚ùå Not supported (CPU-only HNSW)
   - üìâ Potential 1.6-4.9x slower than GPU-accelerated alternatives

3. **Limited Quantization**:
   - ‚ö†Ô∏è Generic quantization only (no SQ, PQ, Binary options)
   - üìä Less control over accuracy/memory trade-offs

4. **Dimension Limits**:
   - ‚ö†Ô∏è 4,096 max dimensions (users requesting 8,192)
   - üìä Modern embedding models (e.g., OpenAI text-embedding-3-large) use 3,072 dimensions (within limit)

5. **Similarity Functions**:
   - ‚ö†Ô∏è Only Cosine and Euclidean supported
   - üìä No Dot Product, Hamming, or Jaccard distance

6. **Memory Configuration**:
   - ‚ö†Ô∏è Complex tuning required for large vector indexes
   - üìñ Requires understanding of `vector.memory_pool.size` configuration

**Source**: [Neo4j Operations Manual - Vector Index Memory](https://neo4j.com/docs/operations-manual/current/performance/vector-index-memory-configuration/)

### 5.3 Best Practices (Neo4j Recommendations)

1. **Enable Quantization**: For memory-constrained environments
2. **Tune HNSW Parameters**:
   - `vector.hnsw.m`: 16 (default) for balanced performance
   - `vector.hnsw.ef_construction`: 200+ for higher recall
3. **Use Hybrid Queries**: Leverage graph relationships for context
4. **Batch Inserts**: 1,000-10,000 nodes per transaction
5. **Monitor Memory**: Configure `vector.memory_pool.size` appropriately

---

## 6. Cost Comparison

### 6.1 Neo4j AuraDB Pricing

**Tiers**:

| Tier | Price | Capacity | Use Case |
|------|-------|----------|----------|
| **Free** | $0 | 200k nodes, 400k relationships | Learning, prototyping |
| **Professional** | $65/month | Variable | Production apps |
| **Enterprise** | Custom | High scale | Large enterprises |

**Pricing Model**:
- ‚úÖ **Flat rate**: Storage, compute, I/O, network, backups included
- ‚úÖ **Hourly metering**: Predictable costs
- ‚úÖ **Pause feature**: Save 80% when idle
- ‚ö†Ô∏è **Professional**: 242% higher than similar services
- ‚ö†Ô∏è **Enterprise**: Very expensive (per user feedback)

**Vector Search Cost**:
- ‚ùå No separate pricing for vector search
- ‚úÖ Included in standard database pricing
- ‚ö†Ô∏è Memory usage depends on vector dimensions and count

**Sources**:
- [Neo4j Pricing Page](https://neo4j.com/pricing/)
- [SaaSWorthy - Neo4j AuraDB Pricing](https://www.saasworthy.com/product/neo4j-aura/pricing)

### 6.2 Milvus Cost Comparison

**Deployment Options**:

| Option | Cost | Management | Use Case |
|--------|------|------------|----------|
| **Open Source** | Free (infrastructure only) | Self-managed | Full control, dev expertise required |
| **Zilliz Cloud** | Pay-as-you-go | Fully managed | Production, no ops team |

**Infrastructure Requirements** (Self-Hosted Milvus):
- **Small Scale** (1M vectors): 4 CPU, 16GB RAM
- **Medium Scale** (10M vectors): 8 CPU, 32GB RAM, GPU recommended
- **Large Scale** (100M vectors): 16+ CPU, 64GB+ RAM, GPU required

**Estimated Monthly Costs** (AWS):

| Scale | Neo4j AuraDB | Milvus Self-Hosted | Zilliz Cloud |
|-------|--------------|-------------------|--------------|
| **1M vectors** | $65-200 | $100-150 | $100-200 |
| **10M vectors** | $200-500 | $200-400 | $300-600 |
| **100M vectors** | $500-2000+ | $500-1500 | $800-2000 |

**Notes**:
- Neo4j costs include graph features (even if unused)
- Milvus self-hosted requires DevOps expertise
- GPU acceleration (Milvus) adds $500-1500/month
- Estimates vary by query volume, region, and configuration

### 6.3 Cost-Benefit Analysis

**When Neo4j is Cost-Effective**:
- ‚úÖ **Graph + Vector Use Case**: Leveraging both capabilities
- ‚úÖ **Small to Medium Scale**: <10M vectors
- ‚úÖ **Hybrid Queries**: Graph traversal + vector search
- ‚úÖ **Managed Service Preference**: No DevOps team

**When Milvus is Cost-Effective**:
- ‚úÖ **Pure Vector Search**: No graph features needed
- ‚úÖ **Large Scale**: 100M+ vectors
- ‚úÖ **GPU Acceleration**: Performance-critical workloads
- ‚úÖ **Advanced Quantization**: Need SQ, PQ, Binary options
- ‚úÖ **DevOps Expertise**: Can manage self-hosted deployment

---

## 7. Comparative Summary: Neo4j vs Milvus

| Feature | Neo4j | Milvus |
|---------|-------|--------|
| **Primary Purpose** | Graph database with vector search | Purpose-built vector database |
| **Algorithm** | HNSW (Lucene) | HNSW, IVF, FLAT, DiskANN, GPU indices |
| **GPU Acceleration** | ‚ùå No | ‚úÖ Yes (GPU-IVF, GPU-CAGRA) |
| **Max Dimensions** | 4,096 | 32,768 |
| **Quantization** | Generic | SQ, PQ, Binary, Scalar Quantization |
| **Similarity Functions** | Cosine, Euclidean | Cosine, Euclidean, IP, Hamming, Jaccard, etc. |
| **100M Vector Benchmarks** | ‚ùå Not published | ‚úÖ Published (VectorDBBench) |
| **ANN Benchmarks** | ‚ùå Not included | ‚úÖ Included |
| **Hybrid Graph + Vector** | ‚úÖ **Unique strength** | ‚ùå No (requires integration with Neo4j/Dgraph) |
| **Batch Operations** | Cypher-based | Dedicated bulk insert API |
| **Pricing (Managed)** | $65-2000+/month | $100-2000+/month |
| **Self-Hosted** | Limited community edition | Fully open-source |
| **Production Adoption** | Graph-focused, vector search emerging | Vector-focused, widely adopted |

---

## 8. Recommendations

### 8.1 Choose Neo4j When:

1. ‚úÖ **Graph + Vector Use Case**: Your data is inherently graph-structured (e.g., social networks, knowledge graphs, recommendation systems)
2. ‚úÖ **Hybrid Queries**: You need to combine semantic similarity with relationship traversal
3. ‚úÖ **GraphRAG**: Building RAG pipelines that benefit from graph context
4. ‚úÖ **Small to Medium Scale**: <10M vectors
5. ‚úÖ **Managed Service**: You prefer fully managed database with minimal ops
6. ‚úÖ **Entity Linking**: Context-aware entity resolution and disambiguation

**Example Use Cases**:
- Knowledge graph Q&A with semantic search
- Recommendation systems (content similarity + user graphs)
- Fraud detection (anomaly detection + transaction networks)
- Regulatory compliance (document similarity + entity relationships)

### 8.2 Choose Milvus When:

1. ‚úÖ **Pure Vector Search**: No graph features needed
2. ‚úÖ **Large Scale**: 100M+ vectors
3. ‚úÖ **Performance Critical**: Need <10ms latency at high QPS
4. ‚úÖ **GPU Acceleration**: Want to leverage GPUs for 2-10x speedup
5. ‚úÖ **Advanced Quantization**: Need SQ, PQ, or Binary quantization
6. ‚úÖ **High Dimensions**: >4,096 dimensions (up to 32,768)
7. ‚úÖ **Open Source**: Want full control and no vendor lock-in

**Example Use Cases**:
- Image/video similarity search at scale
- Semantic search over large document corpora
- Recommendation systems (content-based only)
- Anomaly detection in high-dimensional data
- Real-time personalization engines

### 8.3 Hybrid Architecture (Best of Both Worlds)

**Pattern**: Use Neo4j + Milvus together

```
Milvus: Vector similarity search (fast, scalable)
   ‚Üì
Neo4j: Graph context enrichment (relationships, metadata)
   ‚Üì
LLM: Generate answer with enriched context
```

**Implementation**:
1. Store vectors in Milvus for fast similarity search
2. Store graph relationships in Neo4j
3. Query Milvus for similar entities ‚Üí get IDs
4. Query Neo4j with IDs ‚Üí get graph context
5. Combine results for LLM prompt

**Example**: [Building a GraphRAG Agent with Neo4j and Milvus](https://neo4j.com/blog/developer/graphrag-agent-neo4j-milvus/)

---

## 9. Research Gaps and Future Work

### 9.1 Missing Benchmarks

**Critical Gaps**:
1. ‚ùå No Neo4j benchmarks at 100M+ vector scale
2. ‚ùå No direct Neo4j vs Milvus comparison
3. ‚ùå No QPS/latency data for Neo4j vector search
4. ‚ùå No recall@K analysis for Neo4j HNSW implementation

**Needed Research**:
- Independent benchmark of Neo4j at 10M, 50M, 100M vectors
- Comparative analysis: Neo4j vs Milvus vs Qdrant vs Weaviate
- Cost-per-query analysis for different scales
- Hybrid query performance (graph + vector)

### 9.2 Unanswered Questions

1. **Scalability**: How does Neo4j vector search perform beyond 10M vectors?
2. **Memory Usage**: Actual RAM requirements for 100M √ó 1536D vectors?
3. **Index Build Time**: How long to index 100M vectors?
4. **Query Latency**: p50, p95, p99 latency at various scales?
5. **Concurrent Queries**: QPS under concurrent load?

### 9.3 Recommended Testing

If considering Neo4j for 100M+ vector scale:

**Proof of Concept**:
1. Load 10M vectors ‚Üí measure index build time and RAM usage
2. Benchmark query latency (p50, p95, p99) with realistic queries
3. Test concurrent queries ‚Üí measure QPS degradation
4. Compare with Milvus on same hardware
5. Evaluate cost at projected scale

**Tools**:
- [VectorDBBench](https://github.com/zilliztech/VectorDBBench) - Adapt for Neo4j
- Neo4j's built-in query profiling (`PROFILE` command)
- Custom load testing scripts

---

## 10. Sources and Citations

### Official Documentation

1. [Neo4j Cypher Manual - Vector Indexes](https://neo4j.com/docs/cypher-manual/current/indexes/semantic-indexes/vector-indexes/)
2. [Neo4j Developer Guide - Vector Search](https://neo4j.com/developer/genai-ecosystem/vector-search/)
3. [Neo4j Blog - Native Vector Data Type](https://neo4j.com/blog/developer/introducing-neo4j-native-vector-data-type/)
4. [Neo4j Operations Manual - Vector Index Memory](https://neo4j.com/docs/operations-manual/current/performance/vector-index-memory-configuration/)
5. [Neo4j Pricing Page](https://neo4j.com/pricing/)

### Benchmarks and Comparisons

6. [ANN-Benchmarks](http://ann-benchmarks.com/)
7. [VectorDBBench GitHub](https://github.com/zilliztech/VectorDBBench)
8. [Milvus 2.2 Benchmark Report](https://milvus.io/docs/benchmark.md)
9. [Zilliz Blog - pgvector vs Neo4j](https://zilliz.com/blog/pgvector-vs-neo4j-a-comprehensive-vector-database-comparison)
10. [Zilliz Blog - Qdrant vs Neo4j](https://zilliz.com/blog/qdrant-vs-neo4j-a-comprehensive-vector-database-comparison)

### Community and Third-Party

11. [Medium - Can Neo4j Replace Vector Databases in RAG?](https://medium.com/@jagadeesan.ganesh/can-neo4j-replace-vector-databases-in-retrieval-augmented-generation-rag-pipelines-f973c47c6ef8)
12. [Medium - 10M Nodes Performance](https://medium.com/@kanishksinghpujari/we-indexed-10-million-nodes-in-neo4j-heres-what-happened-to-search-performance-9cd101602560)
13. [NornicDB Benchmark vs Neo4j](https://github.com/orneryd/Mimir/blob/main/nornicdb/BENCHMARK_RESULTS_VS_NEO4J.md)
14. [DB-Engines - Milvus vs Neo4j](https://db-engines.com/en/system/Milvus;Neo4j)

### GraphRAG and Hybrid Search

15. [GraphAcademy - Hybrid Retrieval](https://graphacademy.neo4j.com/courses/genai-workshop-graphrag/2-neo4j-graphrag/5-hybrid-cypher-retriever/)
16. [Neo4j Blog - GraphRAG Python Package](https://neo4j.com/blog/developer/enhancing-hybrid-retrieval-graphrag-python-package/)
17. [Neo4j Blog - GraphRAG Agent with Milvus](https://neo4j.com/blog/developer/graphrag-agent-neo4j-milvus/)

### GitHub Issues and Changelog

18. [GitHub Issue #13406 - Dimension Limit 2048](https://github.com/neo4j/neo4j/issues/13406)
19. [GitHub Issue #13512 - Increase to 8192](https://github.com/neo4j/neo4j/issues/13512)
20. [Neo4j 5 Changelog](https://github.com/neo4j/neo4j/wiki/Neo4j-5-changelog)

### Press and Industry

21. [Neo4j Press Release - Vector Search](https://neo4j.com/press-releases/neo4j-vector-search/)
22. [TechTarget - Neo4j Vector Search](https://www.techtarget.com/searchdatamanagement/news/366549617/Neo4j-adds-vector-search-to-improve-generative-AI-outputs)

---

## 11. Conclusion

Neo4j's vector search capabilities (v5.11+) are **production-ready for hybrid graph + vector use cases at small to medium scale** (<10M vectors). The HybridCypherRetriever pattern is a unique strength, enabling GraphRAG applications that combine semantic similarity with relationship context.

However, **for pure vector search at 100M+ scale**, Milvus remains the superior choice due to:
- GPU acceleration (2-10x speedup)
- Advanced quantization (SQ, PQ, Binary)
- Published benchmarks at 100M+ scale
- Higher dimension limits (32,768 vs 4,096)

**Critical Finding**: The absence of published benchmarks comparing Neo4j vs Milvus at 100M scale is a significant knowledge gap. Organizations planning large-scale deployments should conduct independent benchmarking before committing to Neo4j for vector-only use cases.

**Best Practice**: For applications requiring both graph context and vector search at scale, consider a **hybrid architecture** using Milvus for vector search performance and Neo4j for graph enrichment.

---

**Research Completed**: December 4, 2025
**Next Steps**: Conduct independent benchmarking if planning 100M+ vector deployment with Neo4j.
